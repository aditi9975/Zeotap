{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')\n",
    "products_df = pd.read_csv('Products.csv')\n",
    "\n",
    "# Check the first few rows of each dataset\n",
    "print(customers_df.head())\n",
    "print(transactions_df.head())\n",
    "print(products_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Tenure  Asia  Europe  North America  South America\n",
      "0      C0001     932   0.0     0.0            0.0            1.0\n",
      "1      C0002    1079   1.0     0.0            0.0            0.0\n",
      "2      C0003     326   0.0     0.0            0.0            1.0\n",
      "3      C0004     841   0.0     0.0            0.0            1.0\n",
      "4      C0005     896   1.0     0.0            0.0            0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "# Extract Tenure (number of days since signup)\n",
    "customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])\n",
    "customers_df['Tenure'] = (datetime.now() - customers_df['SignupDate']).dt.days\n",
    "\n",
    "# One-hot encode the 'Region' column\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Corrected argument\n",
    "region_encoded = encoder.fit_transform(customers_df[['Region']])\n",
    "region_df = pd.DataFrame(region_encoded, columns=encoder.categories_[0])\n",
    "\n",
    "# Combine customer features\n",
    "customer_features = pd.concat([customers_df[['CustomerID', 'Tenure']], region_df], axis=1)\n",
    "\n",
    "# Display processed customer data\n",
    "print(customer_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Tenure  Asia  Europe  North America  South America  \\\n",
      "0      C0001     932   0.0     0.0            0.0            1.0   \n",
      "1      C0002    1079   1.0     0.0            0.0            0.0   \n",
      "2      C0003     326   0.0     0.0            0.0            1.0   \n",
      "3      C0004     841   0.0     0.0            0.0            1.0   \n",
      "4      C0005     896   1.0     0.0            0.0            0.0   \n",
      "\n",
      "   TotalAmountSpent  TransactionCount  \n",
      "0           3354.52               5.0  \n",
      "1           1862.74               4.0  \n",
      "2           2725.38               4.0  \n",
      "3           5354.88               8.0  \n",
      "4           2034.24               3.0  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate transaction data by CustomerID\n",
    "transaction_summary = transactions_df.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',  # Total spending\n",
    "    'TransactionID': 'count'  # Total number of transactions\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "transaction_summary.rename(columns={'TotalValue': 'TotalAmountSpent', 'TransactionID': 'TransactionCount'}, inplace=True)\n",
    "\n",
    "# Merge transaction data with customer features\n",
    "customer_data = pd.merge(customer_features, transaction_summary, on='CustomerID', how='left')\n",
    "\n",
    "# Display the updated customer data\n",
    "print(customer_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Tenure  Asia  Europe  North America  South America  \\\n",
      "0      C0001     932   0.0     0.0            0.0            1.0   \n",
      "1      C0002    1079   1.0     0.0            0.0            0.0   \n",
      "2      C0003     326   0.0     0.0            0.0            1.0   \n",
      "3      C0004     841   0.0     0.0            0.0            1.0   \n",
      "4      C0005     896   1.0     0.0            0.0            0.0   \n",
      "\n",
      "   TotalAmountSpent  TransactionCount  Books  Clothing  Electronics  \\\n",
      "0           3354.52               5.0    2.0       0.0          7.0   \n",
      "1           1862.74               4.0    0.0       4.0          0.0   \n",
      "2           2725.38               4.0    0.0       4.0          4.0   \n",
      "3           5354.88               8.0    8.0       0.0          6.0   \n",
      "4           2034.24               3.0    0.0       0.0          4.0   \n",
      "\n",
      "   Home Decor  \n",
      "0         3.0  \n",
      "1         6.0  \n",
      "2         6.0  \n",
      "3         9.0  \n",
      "4         3.0  \n"
     ]
    }
   ],
   "source": [
    "# Merge the transactions with the product data to get product categories\n",
    "product_category_summary = transactions_df.merge(products_df[['ProductID', 'Category']], on='ProductID', how='left')\n",
    "\n",
    "# Aggregate the product category purchases by customer\n",
    "product_category_counts = product_category_summary.groupby(['CustomerID', 'Category']).agg({\n",
    "    'Quantity': 'sum'  # Total quantity purchased for each category\n",
    "}).reset_index()\n",
    "\n",
    "# Pivot the table to create one column for each product category\n",
    "product_category_pivot = product_category_counts.pivot_table(\n",
    "    index='CustomerID', columns='Category', values='Quantity', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Merge product category data with the customer profile\n",
    "customer_data = pd.merge(customer_data, product_category_pivot, on='CustomerID', how='left').fillna(0)\n",
    "\n",
    "# Display the updated customer data\n",
    "print(customer_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.96790277 0.98847588 0.99336859 0.98966494]\n",
      " [0.96790277 1.         0.91871733 0.93259661 0.99393695]\n",
      " [0.98847588 0.91871733 1.         0.99932318 0.95655606]\n",
      " [0.99336859 0.93259661 0.99932318 1.         0.96661686]\n",
      " [0.98966494 0.99393695 0.95655606 0.96661686 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract feature vectors (excluding CustomerID)\n",
    "customer_features = customer_data.drop(columns=['CustomerID'])\n",
    "\n",
    "# Calculate the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(customer_features)\n",
    "\n",
    "# Check the similarity of the first few customers\n",
    "print(similarity_matrix[:5, :5])  # Similarity between the first 5 customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 lookalikes for C0001: [('C0174', 0.9999879436694386), ('C0135', 0.9999844934562775), ('C0139', 0.9999822895308264)]\n",
      "Top 3 lookalikes for C0002: [('C0029', 0.9999664526490727), ('C0025', 0.9999661281475694), ('C0121', 0.9999567212133877)]\n",
      "Top 3 lookalikes for C0003: [('C0148', 0.9999981615583643), ('C0021', 0.999996159357211), ('C0089', 0.9999948868486738)]\n",
      "Top 3 lookalikes for C0004: [('C0167', 0.9999968080694094), ('C0142', 0.999994344111737), ('C0034', 0.999992794365829)]\n",
      "Top 3 lookalikes for C0005: [('C0159', 0.9999921319550306), ('C0176', 0.9999782818287117), ('C0166', 0.9999756615037821)]\n"
     ]
    }
   ],
   "source": [
    "# Get the top 3 most similar customers for each customer\n",
    "top_lookalikes = {}\n",
    "for i in range(len(customer_data)):\n",
    "    # Get similarity scores for customer i\n",
    "    similarity_scores = similarity_matrix[i]\n",
    "    \n",
    "    # Exclude the customer itself by setting its similarity score to -1\n",
    "    similarity_scores[i] = -1\n",
    "\n",
    "    # Get the indices of the top 3 most similar customers\n",
    "    top_indices = similarity_scores.argsort()[-3:][::-1]\n",
    "    \n",
    "    # Store the top 3 lookalikes and their similarity scores\n",
    "    top_lookalikes[customer_data['CustomerID'][i]] = [\n",
    "        (customer_data['CustomerID'][idx], similarity_scores[idx]) for idx in top_indices\n",
    "    ]\n",
    "\n",
    "# Display the top lookalikes for the first 5 customers\n",
    "for customer, lookalikes in list(top_lookalikes.items())[:5]:\n",
    "    print(f\"Top 3 lookalikes for {customer}: {lookalikes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike.csv has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare the data for saving as Lookalike.csv\n",
    "lookalike_data = []\n",
    "for customer, lookalikes in top_lookalikes.items():\n",
    "    for lookalike, score in lookalikes:\n",
    "        lookalike_data.append([customer, lookalike, score])\n",
    "\n",
    "# Create a DataFrame and save it to CSV\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'LookalikeCustomerID', 'SimilarityScore'])\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "print(\"Lookalike.csv has been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Lookalike Model\n",
    "\n",
    "## Objective\n",
    "Build a Lookalike Model that recommends 3 similar customers for each of the first 20 customers based on their demographic profile and transaction history. The model uses both customer and product information to calculate similarity scores and generate personalized customer recommendations.\n",
    "\n",
    "## Process\n",
    "\n",
    "### 1. **Data Preprocessing**:\n",
    "   - **Loaded and cleaned** the `Customers.csv`, `Transactions.csv`, and `Products.csv` datasets.\n",
    "   - **Processed customer data** to create relevant features such as `Tenure` (days since signup) and one-hot encoded `Region`.\n",
    "   - **Aggregated transaction data** to calculate customer metrics like `TotalAmountSpent` and `TransactionCount`.\n",
    "   - **Integrated product data** to calculate the types of products purchased by each customer and aggregated them into product category features.\n",
    "\n",
    "### 2. **Similarity Calculation**:\n",
    "   - **Combined customer profile features**, transaction data, and product purchase patterns into a unified feature vector for each customer.\n",
    "   - **Calculated the Cosine Similarity** between customers to measure their similarity based on their features.\n",
    "\n",
    "### 3. **Lookalike Recommendations**:\n",
    "   - For each of the first 20 customers, **identified the top 3 most similar customers** based on similarity scores.\n",
    "   - **Created a mapping** of each customer to their top 3 lookalike customers with similarity scores.\n",
    "\n",
    "## Deliverables\n",
    "- **Lookalike.csv**: Contains the top 3 most similar customers for each of the first 20 customers, along with similarity scores.\n",
    "- **Python Code**: The full implementation of the Lookalike Model and all relevant steps are provided in the Python script for reproducibility.\n",
    "\n",
    "## Example Insights (Placeholder):\n",
    "- Customers with similar purchasing behavior can be targeted with **similar marketing campaigns**.\n",
    "- Certain **product categories** are preferred by specific customer segments, revealing opportunities for **personalized product recommendations**.\n",
    "- **High-spending customers** can be grouped with lookalike customers for **retention strategies**.\n",
    "\n",
    "## Next Steps\n",
    "Use the generated lookalikes to:\n",
    "- **Improve marketing efforts** by targeting lookalike customers with tailored campaigns.\n",
    "- **Enhance product recommendations** based on similar customer behavior.\n",
    "- **Build personalized customer experiences** leveraging the insights from the lookalike model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
